{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_style_transfer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZblP0MQOmhb",
        "colab_type": "code",
        "outputId": "cdc5c890-d56b-4c35-fdc1-76acb7d89c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "\n",
        "\n",
        "!pip install torch==1.1.0\n",
        "!pip install torchvision==0.2.1\n",
        "import sys\n",
        "print(sys.version) # python 3.6\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as vutils\n",
        "print(torch.__version__) \n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import os, time\n",
        "\n",
        "import itertools\n",
        "import pickle\n",
        "import imageio\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "\n",
        "# You can use whatever display function you want. This is a really simple one that makes decent visualizations\n",
        "def show_imgs(x,epochs,iterations, new_fig=True):\n",
        "    grid = vutils.make_grid(x.detach().cpu(), nrow=8, normalize=False, pad_value=0.3)\n",
        "    grid = grid.transpose(0,2).transpose(0,1) # channels as last dimension\n",
        "    if new_fig:\n",
        "        plt.figure()\n",
        "    plt.imshow(grid.numpy())\n",
        "    #plt.text(0, -20, 'Epoch: ' + str(epochs) + ', ' + 'Iteration: ' + str(iterations), fontsize=20)\n",
        "    plt.savefig('/content/drive/My Drive/GAN_stuff/image_' + str(epochs) + '_' + str(iterations) + '.png')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.17.3)\n",
            "Requirement already satisfied: torchvision==0.2.1 in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (4.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.17.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.2.1) (0.46)\n",
            "3.6.8 (default, Oct  7 2019, 12:59:55) \n",
            "[GCC 8.3.0]\n",
            "1.1.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk2waXdSOvg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# helper function to initialize the weights using a normal distribution. \n",
        "# this was done in the original work (instead of xavier) and has been shown\n",
        "# to help GAN performance\n",
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=32):\n",
        "        super().__init__()\n",
        "        self.conv0 = nn.Conv2d(3, 1024 , 2, 4 ,2 )\n",
        "        self.conv1 = nn.Conv2d(1024, 1024 , 2, 4 ,2 )\n",
        "        self.deconv1 = nn.ConvTranspose2d(1024, d*8, 4, 1, 0)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
        "        #self.deconv5 = nn.ConvTranspose2d(d, 3, 4, 2, 1)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d,3,6,2,37)\n",
        "\n",
        "    # weight_init\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "\n",
        "        #print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.conv0(x))\n",
        "        #print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.deconv1_bn(self.deconv1(x)))\n",
        "        #print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "        #print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "        #print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "        #print(\"G \" + str(x.size()))\n",
        "        x = torch.tanh(self.deconv5(x))\n",
        "        #print(\"G \" + str(x.size()))\n",
        "        \n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=32):\n",
        "        super().__init__()\n",
        "        self.conv0 = nn.Conv2d(3, d , 2, 4 ,2 )\n",
        "        self.conv1 = nn.Conv2d(d, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "    # weight_init\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        #print(\"D \" + str(x.size()))\n",
        "        x = F.leaky_relu(self.conv0(x), 0.2)\n",
        "        #print(\"D \" + str(x.size()))\n",
        "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        #print(\"D \" + str(x.size()))\n",
        "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
        "        #print(\"D \" + str(x.size()))\n",
        "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
        "        #print(\"D \" + str(x.size()))\n",
        "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
        "        #print(\"D \" + str(x.size()))\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "        #print(\"D \" + str(x.size()))\n",
        "        return x\n",
        "\n",
        "#####\n",
        "# instantiate a Generator and Discriminator according to their class definition.\n",
        "#####\n",
        "D=Discriminator()\n",
        "G=Generator()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5KPW7iiPzOT",
        "colab_type": "code",
        "outputId": "54bfe6e9-4821-4d03-ec29-93d2009b8305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "batch_size = 32\n",
        "lr = 0.0002\n",
        "train_epoch = 3\n",
        "\n",
        "import urllib.request\n",
        "from zipfile import ZipFile\n",
        "from torch.utils import data\n",
        "from os import path\n",
        "import imageio\n",
        "img_size = 250\n",
        "\n",
        "#download the data, and change the filepath\n",
        "url='https://thleats-bucket.s3.us-east-2.amazonaws.com/CS/celeba-dataset.zip'\n",
        "url2='https://thleats-bucket.s3.us-east-2.amazonaws.com/celeba_dataset_trans.zip'\n",
        "location = '/content/celeba-dataset.zip'\n",
        "location2='/content/celeba_dataset_trans.zip'\n",
        "\n",
        "if path.exists(location):\n",
        "  print('already downloaded!')\n",
        "else:\n",
        "  print('downloading')\n",
        "  urllib.request.urlretrieve(url,location)\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "  with ZipFile(location, 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()\n",
        "\n",
        "if path.exists(location2):\n",
        "  print('already downloaded!')\n",
        "else:\n",
        "  print('downloading')\n",
        "  urllib.request.urlretrieve(url2,location2)\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "  with ZipFile(location2, 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall('/content/celeba_dataset_trans/celeba_dataset_trans')\n",
        "\n",
        "\n",
        "\n",
        "dataset=datasets.ImageFolder(root='/content/img_align_celeba/',\n",
        "                                      transform=transforms.Compose([transforms.Resize(img_size),\n",
        "                                      transforms.CenterCrop(img_size),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      ]))\n",
        "\n",
        "dataset2=datasets.ImageFolder(root='/content/celeba_dataset_trans/',\n",
        "                                      transform=transforms.Compose([transforms.Resize(img_size),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      ]))\n",
        "\n",
        "\n",
        "##### Create the dataloader #####\n",
        "class Dataset(data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self,dataset,dataset2):\n",
        "    'Initialization'\n",
        "    self.dataset1=dataset\n",
        "    self.dataset2=dataset2\n",
        "  def __len__(self):\n",
        "    'Denotes the total number of samples'\n",
        "    return len(self.dataset2)\n",
        "    #return 1024\n",
        "  def __getitem__(self, index):\n",
        "    'Generates one sample of data'\n",
        "    # Select sample\n",
        "    x,_ = self.dataset1[index+1]\n",
        "    x2,_=self.dataset2[index] \n",
        "    Y = index\n",
        "    return x, x2, Y\n",
        "\n",
        "thing=Dataset(dataset,dataset2)\n",
        "params={'batch_size':batch_size,'shuffle':True}\n",
        "training_generator=data.DataLoader(thing,**params)\n",
        "\n",
        "xbatch, x2, _ = iter(training_generator).next()\n",
        "xbatch.shape\n",
        "D(xbatch)\n",
        "D(xbatch).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already downloaded!\n",
            "already downloaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcem31JVGCAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = Generator(32)\n",
        "D = Discriminator(32)\n",
        "G.weight_init(mean=0.0, std=0.02)\n",
        "D.weight_init(mean=0.0, std=0.02)\n",
        "G = G.cuda()\n",
        "D = D.cuda()\n",
        "\n",
        "# Binary Cross Entropy loss\n",
        "BCE_loss = nn.BCELoss()\n",
        "\n",
        "# Adam optimizer\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aV86RrTGIVS",
        "colab_type": "code",
        "outputId": "e0812213-bec6-4124-ec90-90fb74c8c5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_iter = 0\n",
        "fixed_z_ = torch.randn(32,100,1,1) \n",
        "collect_x_gen = []\n",
        "train_epoch=50\n",
        "import pdb\n",
        "count=0\n",
        "for epoch in range(train_epoch):\n",
        "    D_losses = []\n",
        "    G_losses = []\n",
        "    epoch_start_time = time.time()\n",
        "    for x_, x2_,_ in tqdm(training_generator):\n",
        "        if count==0:\n",
        "          fixed_z_=x_\n",
        "          fixed_z_true=x2_\n",
        "        ######################### train discriminator D ###############################\n",
        "        ###############################################################################\n",
        "        if x_.size()[0]==32:\n",
        "          D.zero_grad()\n",
        "          \n",
        "          mini_batch = x_.size()[0]\n",
        "          ##Set optimizer grads to zero\n",
        "          D_optimizer.zero_grad()\n",
        "          G_optimizer.zero_grad()\n",
        "          #create a random noise\n",
        "          #z = torch.randn(mini_batch,100,1,1)\n",
        "          z=x_\n",
        "          #create the zeros and ones vector for real and fake\n",
        "          y_real=torch.ones(x_.size(0)).cuda()\n",
        "          y_fake=torch.zeros(x_.size(0)).cuda()\n",
        "          #Pass through discriminiator - train it to recognize real images\n",
        "          D_result=D(x2_.cuda()).squeeze(-1).squeeze(-1)\n",
        "          #find the real loss for the discriminator\n",
        "          D_real_loss=BCE_loss(D_result.squeeze(-1),y_real)\n",
        "          #pass the noise through the generator\n",
        "          #pdb.set_trace()\n",
        "          G_result=G(z.cuda())\n",
        "          #pass the Generated data through the discriminator\n",
        "          D_result_G=D(G_result)\n",
        "          #pdb.set_trace()\n",
        "          #calculate how well the discriminator does at recognizing fake images\n",
        "          D_fake_loss=BCE_loss(D_result_G.squeeze(-1).squeeze(-1).squeeze(-1),y_fake)\n",
        "          #calculate the total loss (real + fake) - basically - how good is the discriminator at seeing real from fake\n",
        "          D_train_loss=D_real_loss+D_fake_loss\n",
        "          #backpropagation on teh network\n",
        "          D_train_loss.backward()\n",
        "          #treain the network\n",
        "          D_optimizer.step()\n",
        "          #record the losses\n",
        "          D_losses.append(D_train_loss.item())\n",
        "          #rezero the optimizers\n",
        "          D_optimizer.zero_grad()\n",
        "          G_optimizer.zero_grad()\n",
        "\n",
        "          ######################### train generator G ###############################\n",
        "          ###############################################################################\n",
        "          G.zero_grad()\n",
        "          #create more noise\n",
        "          #z_new = torch.randn(32,100,1,1)\n",
        "          #pass the noise through the generator\n",
        "          G_result_G=G(z.cuda())\n",
        "          #pass the generated data through the discriminator\n",
        "          D_result_2=D(G_result_G)\n",
        "          #find how good the generator is at generating fakes\n",
        "          G_train_loss=BCE_loss(D_result_2.squeeze(-1).squeeze(-1).squeeze(-1),y_real)\n",
        "          #calculate the gradients\n",
        "          G_train_loss.backward()\n",
        "          #train the network\n",
        "          G_optimizer.step()    \n",
        "          #record the stuff\n",
        "          G_losses.append(G_train_loss.item())\n",
        "          \n",
        "\n",
        "          num_iter += 1\n",
        "\n",
        "      # generate a fixed_z_ image and save\n",
        "          if num_iter%8==0:\n",
        "            x_gen = G(fixed_z_.cuda())\n",
        "            collect_x_gen.append(x_gen.detach().clone())\n",
        "            epoch_end_time = time.time()\n",
        "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
        "\n",
        "            # print out statistics\n",
        "            print('[%d/%d] - ptime: %.2f, loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), train_epoch, per_epoch_ptime, torch.mean(torch.FloatTensor(D_losses)),\n",
        "                                                                      torch.mean(torch.FloatTensor(G_losses))))\n",
        "            \n",
        "            show_imgs(x_gen,epoch,num_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 11%|█         | 7/65 [00:09<01:18,  1.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/50] - ptime: 10.79, loss_d: 1.742, loss_g: 0.979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            " 23%|██▎       | 15/65 [00:20<01:07,  1.35s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/50] - ptime: 21.83, loss_d: 1.528, loss_g: 1.198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 23/65 [00:31<00:56,  1.35s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/50] - ptime: 32.89, loss_d: 1.460, loss_g: 1.335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 31/65 [00:42<00:45,  1.34s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/50] - ptime: 43.92, loss_d: 1.428, loss_g: 1.358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 39/65 [00:53<00:34,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/50] - ptime: 54.85, loss_d: 1.403, loss_g: 1.345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 47/65 [01:04<00:24,  1.34s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/50] - ptime: 65.82, loss_d: 1.403, loss_g: 1.305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 55/65 [01:15<00:13,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/50] - ptime: 76.78, loss_d: 1.408, loss_g: 1.263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 63/65 [01:26<00:02,  1.34s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/50] - ptime: 87.76, loss_d: 1.415, loss_g: 1.236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 65/65 [01:28<00:00,  1.03s/it]\n",
            " 11%|█         | 7/65 [00:09<01:16,  1.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2/50] - ptime: 10.63, loss_d: 1.525, loss_g: 0.945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            " 23%|██▎       | 15/65 [00:20<01:06,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2/50] - ptime: 21.54, loss_d: 1.509, loss_g: 0.945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 23/65 [00:31<00:55,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2/50] - ptime: 32.44, loss_d: 1.498, loss_g: 0.930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 31/65 [00:42<00:45,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2/50] - ptime: 43.35, loss_d: 1.496, loss_g: 0.909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 39/65 [00:52<00:34,  1.34s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2/50] - ptime: 54.31, loss_d: 1.499, loss_g: 0.889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 47/65 [01:03<00:24,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2/50] - ptime: 65.25, loss_d: 1.491, loss_g: 0.871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 55/65 [01:14<00:13,  1.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2/50] - ptime: 76.21, loss_d: 1.489, loss_g: 0.864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            " 97%|█████████▋| 63/65 [01:25<00:02,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2/50] - ptime: 87.13, loss_d: 1.482, loss_g: 0.861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 65/65 [01:27<00:00,  1.03s/it]\n",
            " 11%|█         | 7/65 [00:09<01:17,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3/50] - ptime: 10.65, loss_d: 1.403, loss_g: 0.823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 15/65 [00:20<01:07,  1.34s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3/50] - ptime: 21.62, loss_d: 1.419, loss_g: 0.835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 23/65 [00:31<00:56,  1.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3/50] - ptime: 32.56, loss_d: 1.422, loss_g: 0.820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            " 48%|████▊     | 31/65 [00:42<00:45,  1.35s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3/50] - ptime: 43.66, loss_d: 1.423, loss_g: 0.821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 39/65 [00:53<00:34,  1.33s/it]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3/50] - ptime: 54.56, loss_d: 1.426, loss_g: 0.817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 47/65 [01:04<00:24,  1.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3/50] - ptime: 65.51, loss_d: 1.426, loss_g: 0.812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            " 85%|████████▍ | 55/65 [01:15<00:13,  1.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3/50] - ptime: 76.53, loss_d: 1.427, loss_g: 0.805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            " 97%|█████████▋| 63/65 [01:26<00:02,  1.34s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3/50] - ptime: 87.49, loss_d: 1.428, loss_g: 0.800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 65/65 [01:27<00:00,  1.03s/it]\n",
            " 11%|█         | 7/65 [00:09<01:16,  1.32s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4/50] - ptime: 10.62, loss_d: 1.420, loss_g: 0.758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 15/65 [00:20<01:06,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4/50] - ptime: 21.52, loss_d: 1.422, loss_g: 0.772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 23/65 [00:31<00:55,  1.32s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4/50] - ptime: 32.35, loss_d: 1.425, loss_g: 0.770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 31/65 [00:41<00:45,  1.34s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4/50] - ptime: 43.32, loss_d: 1.428, loss_g: 0.767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 39/65 [00:52<00:34,  1.33s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4/50] - ptime: 54.25, loss_d: 1.427, loss_g: 0.769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 43/65 [00:58<00:29,  1.36s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW_tDbA2C5DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjZzDAfWqO5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_result.size()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}